{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from model import *\n",
    "from utils import *\n",
    "from gen_img import gen_imgs\n",
    "import datetime\n",
    "from save_model import replace_model_if_better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data pickle...\n",
      "Data pickle loaded.\n",
      "(11844, 7, 7, 3)\n",
      "(2961, 7, 7, 3)\n",
      "(3101, 7, 7, 3)\n",
      "(11844, 4)\n",
      "(2961, 4)\n",
      "(3101, 4)\n"
     ]
    }
   ],
   "source": [
    "# Create result folders \n",
    "save_path = join(get_save_path(), 'SingleFrameFourier')\n",
    "new_path = join(save_path, 'best_val')\n",
    "time = str(datetime.datetime.now()).replace(' ', '_')\n",
    "workpath = join(save_path, time)\n",
    "ensure_dir(new_path)\n",
    "ensure_dir(workpath)\n",
    "ensure_dir(save_path)\n",
    "\n",
    "imgs = gen_imgs('single_frame_fourier', normalize=True)\n",
    "X_train = imgs['X_train_imgs']\n",
    "X_train = np.insert(X_train, X_train.shape[1], 0.0, axis=1)\n",
    "# X_train = np.insert(X_train, X_train.shape[1], 0.0, axis=1)\n",
    "# X_train = np.insert(X_train, 0, 0.0, axis=1)\n",
    "# X_train = np.insert(X_train, X_train.shape[1], 0.0, axis=1)\n",
    "# X_train = np.insert(X_train, 0, 0.0, axis=1)\n",
    "# X_train = np.insert(X_train, X_train.shape[2], 0.0, axis=2)\n",
    "# X_train = np.insert(X_train, 0, 0.0, axis=2)\n",
    "# X_train = np.insert(X_train, X_train.shape[2], 0.0, axis=2)\n",
    "# X_train = np.insert(X_train, 0, 0.0, axis=2)\n",
    "\n",
    "X_val = imgs['X_valid_imgs']\n",
    "X_val = np.insert(X_val, X_val.shape[1], 0.0, axis=1)\n",
    "# X_val = np.insert(X_val, X_val.shape[1], 0.0, axis=1)\n",
    "# X_val = np.insert(X_val, 0, 0.0, axis=1)\n",
    "# X_val = np.insert(X_val, X_val.shape[1], 0.0, axis=1)\n",
    "# X_val = np.insert(X_val, 0, 0.0, axis=1)\n",
    "# X_val = np.insert(X_val, X_val.shape[2], 0.0, axis=2)\n",
    "# X_val = np.insert(X_val, 0, 0.0, axis=2)\n",
    "# X_val = np.insert(X_val, X_val.shape[2], 0.0, axis=2)\n",
    "# X_val = np.insert(X_val, 0, 0.0, axis=2)\n",
    "\n",
    "X_test = imgs['X_test_imgs']\n",
    "X_test = np.insert(X_test, X_test.shape[1], 0.0, axis=1)\n",
    "# X_test = np.insert(X_test, X_test.shape[1], 0.0, axis=1)\n",
    "# X_test = np.insert(X_test, 0, 0.0, axis=1)\n",
    "# X_test = np.insert(X_test, X_test.shape[1], 0.0, axis=1)\n",
    "# X_test = np.insert(X_test, 0, 0.0, axis=1)\n",
    "# X_test = np.insert(X_test, X_test.shape[2], 0.0, axis=2)\n",
    "# X_test = np.insert(X_test, 0, 0.0, axis=2)\n",
    "# X_test = np.insert(X_test, X_test.shape[2], 0.0, axis=2)\n",
    "# X_test = np.insert(X_test, 0, 0.0, axis=2)\n",
    "\n",
    "y_train = imgs['y_train']\n",
    "y_val = imgs['y_val']\n",
    "y_test = imgs['y_test']\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    # Network\n",
    "    'num_inputs': X_train.shape[0],\n",
    "    'input_shape': (X_train.shape[0], X_train.shape[1],X_train.shape[2],X_train.shape[3]),\n",
    "    'epochs': 100,\n",
    "    'dropout': 0.3,\n",
    "    'batch_size': 128,\n",
    "    'l2': 0.01,\n",
    "    'lr': 0.001,\n",
    "    'MLP': False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 6, 6, 128)\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 6, 6, 128)         1664      \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 36, 128)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 36, 128)           512       \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 5, 5, 64)          32832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 43,364\n",
      "Trainable params: 43,108\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "Train on 11844 samples, validate on 2961 samples\n",
      "Epoch 1/100\n",
      "11844/11844 [==============================] - 1s 77us/step - loss: 1.3851 - accuracy: 0.2743 - val_loss: 1.3838 - val_accuracy: 0.2557\n",
      "Epoch 2/100\n",
      "11844/11844 [==============================] - 1s 54us/step - loss: 1.3768 - accuracy: 0.2828 - val_loss: 1.3793 - val_accuracy: 0.3235\n",
      "Epoch 3/100\n",
      "11844/11844 [==============================] - 1s 54us/step - loss: 1.3722 - accuracy: 0.2978 - val_loss: 1.3818 - val_accuracy: 0.2942\n",
      "Epoch 4/100\n",
      "11844/11844 [==============================] - 1s 55us/step - loss: 1.3679 - accuracy: 0.3094 - val_loss: 1.3759 - val_accuracy: 0.3077\n",
      "Epoch 5/100\n",
      "11844/11844 [==============================] - 1s 55us/step - loss: 1.3655 - accuracy: 0.3164 - val_loss: 1.3761 - val_accuracy: 0.3303\n",
      "Epoch 6/100\n",
      "11844/11844 [==============================] - 1s 54us/step - loss: 1.3628 - accuracy: 0.3181 - val_loss: 1.3674 - val_accuracy: 0.3175\n",
      "Epoch 7/100\n",
      "11844/11844 [==============================] - 1s 56us/step - loss: 1.3602 - accuracy: 0.3191 - val_loss: 1.3820 - val_accuracy: 0.2682\n",
      "Epoch 8/100\n",
      "11844/11844 [==============================] - 1s 54us/step - loss: 1.3593 - accuracy: 0.3222 - val_loss: 1.3693 - val_accuracy: 0.3195\n",
      "Epoch 9/100\n",
      "11844/11844 [==============================] - 1s 54us/step - loss: 1.3549 - accuracy: 0.3295 - val_loss: 1.3615 - val_accuracy: 0.3168\n",
      "Epoch 10/100\n",
      "11844/11844 [==============================] - 1s 55us/step - loss: 1.3516 - accuracy: 0.3354 - val_loss: 1.3719 - val_accuracy: 0.3050\n",
      "Epoch 11/100\n",
      "11844/11844 [==============================] - 1s 57us/step - loss: 1.3495 - accuracy: 0.3381 - val_loss: 1.3715 - val_accuracy: 0.3185\n",
      "Epoch 12/100\n",
      "11844/11844 [==============================] - 1s 55us/step - loss: 1.3406 - accuracy: 0.3555 - val_loss: 1.3732 - val_accuracy: 0.3259\n",
      "Epoch 13/100\n",
      "11844/11844 [==============================] - 1s 56us/step - loss: 1.3386 - accuracy: 0.3589 - val_loss: 1.3804 - val_accuracy: 0.3121\n",
      "Epoch 14/100\n",
      "11844/11844 [==============================] - 1s 57us/step - loss: 1.3375 - accuracy: 0.3593 - val_loss: 1.3558 - val_accuracy: 0.3425\n",
      "Epoch 15/100\n",
      "11844/11844 [==============================] - 1s 56us/step - loss: 1.3337 - accuracy: 0.3684 - val_loss: 1.3437 - val_accuracy: 0.3705\n",
      "Epoch 16/100\n",
      "11844/11844 [==============================] - 1s 56us/step - loss: 1.3282 - accuracy: 0.3761 - val_loss: 1.3612 - val_accuracy: 0.3354\n",
      "Epoch 17/100\n",
      "11844/11844 [==============================] - 1s 56us/step - loss: 1.3240 - accuracy: 0.3792 - val_loss: 1.3448 - val_accuracy: 0.3617\n",
      "Epoch 18/100\n",
      "11844/11844 [==============================] - 1s 55us/step - loss: 1.3226 - accuracy: 0.3798 - val_loss: 1.3552 - val_accuracy: 0.3394\n",
      "Epoch 19/100\n",
      "11844/11844 [==============================] - 1s 58us/step - loss: 1.3148 - accuracy: 0.3910 - val_loss: 1.3409 - val_accuracy: 0.3701\n",
      "Epoch 20/100\n",
      "11844/11844 [==============================] - 1s 57us/step - loss: 1.3144 - accuracy: 0.3911 - val_loss: 1.3678 - val_accuracy: 0.3259\n",
      "Epoch 21/100\n",
      "11844/11844 [==============================] - 1s 55us/step - loss: 1.3135 - accuracy: 0.3945 - val_loss: 1.3427 - val_accuracy: 0.3691\n",
      "Epoch 22/100\n",
      "11844/11844 [==============================] - 1s 55us/step - loss: 1.3081 - accuracy: 0.3947 - val_loss: 1.3372 - val_accuracy: 0.3573\n",
      "Epoch 23/100\n",
      "11844/11844 [==============================] - 1s 56us/step - loss: 1.3010 - accuracy: 0.4092 - val_loss: 1.3424 - val_accuracy: 0.3617\n",
      "Epoch 24/100\n",
      "11844/11844 [==============================] - 1s 56us/step - loss: 1.3003 - accuracy: 0.4077 - val_loss: 1.3360 - val_accuracy: 0.3661\n",
      "Epoch 25/100\n",
      "11844/11844 [==============================] - 1s 55us/step - loss: 1.3000 - accuracy: 0.4097 - val_loss: 1.3417 - val_accuracy: 0.3526\n",
      "Epoch 26/100\n",
      "11844/11844 [==============================] - 1s 56us/step - loss: 1.2945 - accuracy: 0.4154 - val_loss: 1.3368 - val_accuracy: 0.3718\n",
      "Epoch 27/100\n",
      "11844/11844 [==============================] - 1s 57us/step - loss: 1.2923 - accuracy: 0.4172 - val_loss: 1.3389 - val_accuracy: 0.3637\n",
      "Epoch 28/100\n",
      "11844/11844 [==============================] - 1s 56us/step - loss: 1.2928 - accuracy: 0.4211 - val_loss: 1.3400 - val_accuracy: 0.3563\n",
      "Epoch 29/100\n",
      "11844/11844 [==============================] - 1s 58us/step - loss: 1.2882 - accuracy: 0.4276 - val_loss: 1.3399 - val_accuracy: 0.3634\n",
      "Epoch 30/100\n",
      "11844/11844 [==============================] - 1s 56us/step - loss: 1.2873 - accuracy: 0.4227 - val_loss: 1.3442 - val_accuracy: 0.3614\n",
      "Epoch 31/100\n",
      "11844/11844 [==============================] - 1s 54us/step - loss: 1.2827 - accuracy: 0.4296 - val_loss: 1.3335 - val_accuracy: 0.3769\n",
      "Epoch 32/100\n",
      "11844/11844 [==============================] - 1s 55us/step - loss: 1.2726 - accuracy: 0.4421 - val_loss: 1.3299 - val_accuracy: 0.3891\n",
      "Epoch 33/100\n",
      "11844/11844 [==============================] - 1s 54us/step - loss: 1.2771 - accuracy: 0.4383 - val_loss: 1.3463 - val_accuracy: 0.3668\n",
      "Epoch 34/100\n",
      "11844/11844 [==============================] - 1s 55us/step - loss: 1.2701 - accuracy: 0.4433 - val_loss: 1.3432 - val_accuracy: 0.3593\n",
      "Epoch 35/100\n",
      "11844/11844 [==============================] - 1s 55us/step - loss: 1.2740 - accuracy: 0.4406 - val_loss: 1.3533 - val_accuracy: 0.3553\n",
      "Epoch 36/100\n",
      "11844/11844 [==============================] - 1s 55us/step - loss: 1.2659 - accuracy: 0.4516 - val_loss: 1.3406 - val_accuracy: 0.3634\n",
      "Epoch 37/100\n",
      "11844/11844 [==============================] - 1s 57us/step - loss: 1.2656 - accuracy: 0.4573 - val_loss: 1.3355 - val_accuracy: 0.3644\n",
      "Epoch 38/100\n",
      "11844/11844 [==============================] - 1s 58us/step - loss: 1.2645 - accuracy: 0.4551 - val_loss: 1.3577 - val_accuracy: 0.3485\n",
      "Epoch 39/100\n",
      "11844/11844 [==============================] - 1s 57us/step - loss: 1.2594 - accuracy: 0.4590 - val_loss: 1.3351 - val_accuracy: 0.3725\n",
      "Epoch 40/100\n",
      "11844/11844 [==============================] - 1s 57us/step - loss: 1.2599 - accuracy: 0.4610 - val_loss: 1.3428 - val_accuracy: 0.3674\n",
      "Epoch 41/100\n",
      "11844/11844 [==============================] - 1s 57us/step - loss: 1.2602 - accuracy: 0.4554 - val_loss: 1.3314 - val_accuracy: 0.3789\n",
      "Epoch 42/100\n",
      "11844/11844 [==============================] - 1s 57us/step - loss: 1.2534 - accuracy: 0.4650 - val_loss: 1.3277 - val_accuracy: 0.3766\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11844/11844 [==============================] - 1s 57us/step - loss: 1.2518 - accuracy: 0.4669 - val_loss: 1.3402 - val_accuracy: 0.3654\n",
      "Epoch 44/100\n",
      "11844/11844 [==============================] - 1s 55us/step - loss: 1.2503 - accuracy: 0.4737 - val_loss: 1.3392 - val_accuracy: 0.3674\n",
      "Epoch 45/100\n",
      "11844/11844 [==============================] - 1s 58us/step - loss: 1.2466 - accuracy: 0.4740 - val_loss: 1.3347 - val_accuracy: 0.3624\n",
      "Epoch 46/100\n",
      "11844/11844 [==============================] - 1s 56us/step - loss: 1.2456 - accuracy: 0.4766 - val_loss: 1.3329 - val_accuracy: 0.3705\n",
      "Epoch 47/100\n",
      "11844/11844 [==============================] - 1s 58us/step - loss: 1.2439 - accuracy: 0.4791 - val_loss: 1.3435 - val_accuracy: 0.3573\n",
      "Epoch 48/100\n",
      "11844/11844 [==============================] - 1s 56us/step - loss: 1.2383 - accuracy: 0.4856 - val_loss: 1.3451 - val_accuracy: 0.3661\n",
      "Epoch 49/100\n",
      "11844/11844 [==============================] - 1s 56us/step - loss: 1.2436 - accuracy: 0.4798 - val_loss: 1.3414 - val_accuracy: 0.3516\n",
      "Epoch 50/100\n",
      "11844/11844 [==============================] - 1s 55us/step - loss: 1.2385 - accuracy: 0.4806 - val_loss: 1.3570 - val_accuracy: 0.3509\n",
      "Epoch 51/100\n",
      "11844/11844 [==============================] - 1s 55us/step - loss: 1.2409 - accuracy: 0.4806 - val_loss: 1.3411 - val_accuracy: 0.3644\n",
      "Epoch 52/100\n",
      "11844/11844 [==============================] - 1s 57us/step - loss: 1.2376 - accuracy: 0.4843 - val_loss: 1.3366 - val_accuracy: 0.3762\n",
      "Epoch 53/100\n",
      "11844/11844 [==============================] - 1s 54us/step - loss: 1.2350 - accuracy: 0.4861 - val_loss: 1.3541 - val_accuracy: 0.3587\n",
      "Epoch 54/100\n",
      "11844/11844 [==============================] - 1s 54us/step - loss: 1.2319 - accuracy: 0.4911 - val_loss: 1.3431 - val_accuracy: 0.3593\n",
      "Epoch 55/100\n",
      "11844/11844 [==============================] - 1s 54us/step - loss: 1.2317 - accuracy: 0.4916 - val_loss: 1.3499 - val_accuracy: 0.3600\n",
      "Epoch 56/100\n",
      "11844/11844 [==============================] - 1s 54us/step - loss: 1.2296 - accuracy: 0.4930 - val_loss: 1.3422 - val_accuracy: 0.3718\n",
      "Epoch 57/100\n",
      "11844/11844 [==============================] - 1s 55us/step - loss: 1.2347 - accuracy: 0.4889 - val_loss: 1.3358 - val_accuracy: 0.3725\n",
      "Epoch 58/100\n",
      "11844/11844 [==============================] - 1s 55us/step - loss: 1.2281 - accuracy: 0.4929 - val_loss: 1.3430 - val_accuracy: 0.3647\n",
      "Epoch 59/100\n",
      "11844/11844 [==============================] - 1s 56us/step - loss: 1.2248 - accuracy: 0.4997 - val_loss: 1.3528 - val_accuracy: 0.3506\n",
      "Epoch 60/100\n",
      "11844/11844 [==============================] - 1s 58us/step - loss: 1.2227 - accuracy: 0.5027 - val_loss: 1.3526 - val_accuracy: 0.3620\n",
      "Epoch 61/100\n",
      "11844/11844 [==============================] - 1s 54us/step - loss: 1.2262 - accuracy: 0.4987 - val_loss: 1.3522 - val_accuracy: 0.3678\n",
      "Epoch 62/100\n",
      "11844/11844 [==============================] - 1s 54us/step - loss: 1.2180 - accuracy: 0.5075 - val_loss: 1.3395 - val_accuracy: 0.3671\n",
      "Epoch 63/100\n",
      "11844/11844 [==============================] - 1s 56us/step - loss: 1.2189 - accuracy: 0.5072 - val_loss: 1.3649 - val_accuracy: 0.3495\n",
      "Epoch 64/100\n",
      "11844/11844 [==============================] - 1s 54us/step - loss: 1.2237 - accuracy: 0.5037 - val_loss: 1.3400 - val_accuracy: 0.3715\n",
      "Epoch 65/100\n",
      "11844/11844 [==============================] - 1s 54us/step - loss: 1.2186 - accuracy: 0.5043 - val_loss: 1.3426 - val_accuracy: 0.3739\n",
      "Epoch 66/100\n",
      "11844/11844 [==============================] - 1s 54us/step - loss: 1.2135 - accuracy: 0.5125 - val_loss: 1.3607 - val_accuracy: 0.3519\n",
      "Epoch 67/100\n",
      "11844/11844 [==============================] - 1s 54us/step - loss: 1.2174 - accuracy: 0.5076 - val_loss: 1.3503 - val_accuracy: 0.3607\n",
      "Epoch 68/100\n",
      "11844/11844 [==============================] - 1s 54us/step - loss: 1.2183 - accuracy: 0.5061 - val_loss: 1.3498 - val_accuracy: 0.3678\n",
      "Epoch 69/100\n",
      "11844/11844 [==============================] - 1s 56us/step - loss: 1.2145 - accuracy: 0.5109 - val_loss: 1.3591 - val_accuracy: 0.3637\n",
      "Epoch 70/100\n",
      "11844/11844 [==============================] - 1s 58us/step - loss: 1.2070 - accuracy: 0.5178 - val_loss: 1.3373 - val_accuracy: 0.3823\n",
      "Epoch 71/100\n",
      "11844/11844 [==============================] - 1s 56us/step - loss: 1.2143 - accuracy: 0.5127 - val_loss: 1.3583 - val_accuracy: 0.3573\n",
      "Epoch 72/100\n",
      "11844/11844 [==============================] - 1s 54us/step - loss: 1.2119 - accuracy: 0.5155 - val_loss: 1.3445 - val_accuracy: 0.3661\n",
      "Epoch 73/100\n",
      "11844/11844 [==============================] - 1s 54us/step - loss: 1.2071 - accuracy: 0.5205 - val_loss: 1.3494 - val_accuracy: 0.3634\n",
      "Epoch 74/100\n",
      "11844/11844 [==============================] - 1s 54us/step - loss: 1.2093 - accuracy: 0.5180 - val_loss: 1.3458 - val_accuracy: 0.3725\n",
      "Epoch 75/100\n",
      "11844/11844 [==============================] - 1s 54us/step - loss: 1.2063 - accuracy: 0.5219 - val_loss: 1.3510 - val_accuracy: 0.3610\n",
      "Epoch 76/100\n",
      "11844/11844 [==============================] - 1s 54us/step - loss: 1.2077 - accuracy: 0.5181 - val_loss: 1.3623 - val_accuracy: 0.3506\n",
      "Epoch 77/100\n",
      "11844/11844 [==============================] - 1s 55us/step - loss: 1.2085 - accuracy: 0.5155 - val_loss: 1.3528 - val_accuracy: 0.3641\n",
      "Epoch 78/100\n",
      "11844/11844 [==============================] - 1s 57us/step - loss: 1.2045 - accuracy: 0.5248 - val_loss: 1.3595 - val_accuracy: 0.3634\n",
      "Epoch 79/100\n",
      "11844/11844 [==============================] - 1s 56us/step - loss: 1.2018 - accuracy: 0.5268 - val_loss: 1.3509 - val_accuracy: 0.3614\n",
      "Epoch 80/100\n",
      "11844/11844 [==============================] - 1s 56us/step - loss: 1.1930 - accuracy: 0.5344 - val_loss: 1.3558 - val_accuracy: 0.3563\n",
      "Epoch 81/100\n",
      "11844/11844 [==============================] - 1s 56us/step - loss: 1.2099 - accuracy: 0.5116 - val_loss: 1.3484 - val_accuracy: 0.3607\n",
      "Epoch 82/100\n",
      "11844/11844 [==============================] - 1s 57us/step - loss: 1.1990 - accuracy: 0.5268 - val_loss: 1.3588 - val_accuracy: 0.3593\n",
      "Epoch 83/100\n",
      "11844/11844 [==============================] - 1s 57us/step - loss: 1.1978 - accuracy: 0.5307 - val_loss: 1.3579 - val_accuracy: 0.3509\n",
      "Epoch 84/100\n",
      "11844/11844 [==============================] - 1s 58us/step - loss: 1.1963 - accuracy: 0.5309 - val_loss: 1.3647 - val_accuracy: 0.3560\n",
      "Epoch 85/100\n",
      "11844/11844 [==============================] - 1s 56us/step - loss: 1.1931 - accuracy: 0.5343 - val_loss: 1.3584 - val_accuracy: 0.3536\n",
      "Epoch 86/100\n",
      "11844/11844 [==============================] - 1s 55us/step - loss: 1.1970 - accuracy: 0.5281 - val_loss: 1.3606 - val_accuracy: 0.3512\n",
      "Epoch 87/100\n",
      "11844/11844 [==============================] - 1s 56us/step - loss: 1.1948 - accuracy: 0.5318 - val_loss: 1.3664 - val_accuracy: 0.3492\n",
      "Epoch 88/100\n",
      "11844/11844 [==============================] - 1s 56us/step - loss: 1.1972 - accuracy: 0.5305 - val_loss: 1.3625 - val_accuracy: 0.3418\n",
      "Epoch 89/100\n",
      "11844/11844 [==============================] - 1s 55us/step - loss: 1.1945 - accuracy: 0.5306 - val_loss: 1.3525 - val_accuracy: 0.3641\n",
      "Epoch 90/100\n",
      "11844/11844 [==============================] - 1s 55us/step - loss: 1.1939 - accuracy: 0.5322 - val_loss: 1.3609 - val_accuracy: 0.3556\n",
      "Epoch 91/100\n",
      "11844/11844 [==============================] - 1s 57us/step - loss: 1.1895 - accuracy: 0.5376 - val_loss: 1.3660 - val_accuracy: 0.3502\n",
      "Epoch 92/100\n",
      "11844/11844 [==============================] - 1s 56us/step - loss: 1.1927 - accuracy: 0.5359 - val_loss: 1.3558 - val_accuracy: 0.3512\n",
      "Epoch 93/100\n",
      "11844/11844 [==============================] - 1s 57us/step - loss: 1.1922 - accuracy: 0.5350 - val_loss: 1.3588 - val_accuracy: 0.3411\n",
      "Epoch 94/100\n",
      "11844/11844 [==============================] - 1s 56us/step - loss: 1.1958 - accuracy: 0.5307 - val_loss: 1.3622 - val_accuracy: 0.3536\n",
      "Epoch 95/100\n",
      "11844/11844 [==============================] - 1s 55us/step - loss: 1.1946 - accuracy: 0.5348 - val_loss: 1.3500 - val_accuracy: 0.3668\n",
      "Epoch 96/100\n",
      "11844/11844 [==============================] - 1s 55us/step - loss: 1.1932 - accuracy: 0.5359 - val_loss: 1.3663 - val_accuracy: 0.3519\n",
      "Epoch 97/100\n",
      "11844/11844 [==============================] - 1s 56us/step - loss: 1.1951 - accuracy: 0.5297 - val_loss: 1.3573 - val_accuracy: 0.3570\n",
      "Epoch 98/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11844/11844 [==============================] - 1s 55us/step - loss: 1.1917 - accuracy: 0.5379 - val_loss: 1.3618 - val_accuracy: 0.3637\n",
      "Epoch 99/100\n",
      "11844/11844 [==============================] - 1s 56us/step - loss: 1.1905 - accuracy: 0.5373 - val_loss: 1.3475 - val_accuracy: 0.3695\n",
      "Epoch 100/100\n",
      "11844/11844 [==============================] - 1s 56us/step - loss: 1.1965 - accuracy: 0.5312 - val_loss: 1.3467 - val_accuracy: 0.3688\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7eff882342e8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SingleFrameFourier = SingleFrameFourier()\n",
    "SingleFrameFourier.build_model(config)\n",
    "SingleFrameFourier.train(X_train, y_train, X_val, y_val, config, save_dir=workpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3101/3101 [==============================] - 0s 25us/step\n",
      "Raw Acc result: 0.3673008680343628\n",
      "Majority Vote result: 0.4288939051918736\n",
      "Old model exists. Comparing performance.\n",
      "New model is better than the old one. Replacing the old model with the new model.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = [SingleFrameFourier.predict(X_test[i::443], 0) for i in range(443)]\n",
    "majority_pred = []\n",
    "for pred in preds:\n",
    "    arg_maxes = [np.argmax(p) for p in pred]\n",
    "    votes = np.bincount(arg_maxes)\n",
    "    out = np.ndarray(shape=(4,), buffer=np.zeros(4), dtype=int)\n",
    "    out[votes.argmax()] = 1\n",
    "    majority_pred.append(out)\n",
    "result = [(a == b).all() for a, b in zip(majority_pred, y_test[0:443])]\n",
    "raw = SingleFrameFourier.evaluate(X_test, y_test)\n",
    "print(\"Raw Acc result: {}\".format(raw[1]))\n",
    "print(\"Majority Vote result: {}\".format(np.mean(result)))\n",
    "filepath = join(save_path, 'SingleFrameFourier.pickle')\n",
    "replace_model_if_better(filepath, np.mean(result), SingleFrameFourier, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
