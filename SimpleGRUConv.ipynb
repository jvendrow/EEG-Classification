{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from model import *\n",
    "import datetime\n",
    "from utils import *\n",
    "from preprocessing import *\n",
    "import random\n",
    "import glob\n",
    "from os.path import join, getctime, basename\n",
    "from load_data import load_data\n",
    "from save_model import replace_model_if_better\n",
    "from keras.models import load_model\n",
    "from shutil import rmtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create result folders \n",
    "save_path = join(get_save_path(), 'SimpleConvGRU')\n",
    "new_path = join(save_path, 'best_val')\n",
    "time = str(datetime.datetime.now()).replace(' ', '_')\n",
    "workpath = join(save_path, time)\n",
    "ensure_dir(new_path)\n",
    "ensure_dir(workpath)\n",
    "ensure_dir(save_path)\n",
    "\n",
    "# Load preprocessed data\n",
    "aug_data = load_data_pickle(get_save_path())\n",
    "total_X_test = aug_data['total_X_test']\n",
    "total_y_test = aug_data['total_y_test']\n",
    "total_X_train = aug_data['total_X_train']\n",
    "total_y_train = aug_data['total_y_train']\n",
    "total_X_val = aug_data['total_X_val']\n",
    "total_y_val = aug_data['total_y_val']\n",
    "total_X_train = np.transpose(total_X_train, (0, 2, 1))\n",
    "total_X_val = np.transpose(total_X_val, (0, 2, 1))\n",
    "total_X_test = np.transpose(total_X_test, (0, 2, 1))\n",
    "print(total_X_train.shape)\n",
    "print(total_y_train.shape)\n",
    "print(total_X_test.shape)\n",
    "print(total_y_test.shape)\n",
    "print(total_X_val.shape)\n",
    "print(total_y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    # Network\n",
    "    'num_inputs': total_X_train.shape[0],\n",
    "    'input_shape': (total_X_train.shape[1],total_X_train.shape[2],1),\n",
    "    'epochs': 50,\n",
    "    'dropout': 0.3,\n",
    "    'batch_size': 320,\n",
    "    'l2': 0.01,\n",
    "    'lr': 0.001\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data pickle...\n",
      "Data pickle loaded.\n",
      "(11844, 100, 22)\n",
      "(11844, 4)\n",
      "(3101, 100, 22)\n",
      "(3101, 4)\n",
      "(2961, 100, 22)\n",
      "(2961, 4)\n"
     ]
    }
   ],
   "source": [
    "# Create result folders \n",
    "save_path = join(get_save_path(), 'SimpleConvGRU')\n",
    "new_path = join(save_path, 'best_val')\n",
    "time = str(datetime.datetime.now()).replace(' ', '_')\n",
    "workpath = join(save_path, time)\n",
    "ensure_dir(new_path)\n",
    "ensure_dir(workpath)\n",
    "ensure_dir(save_path)\n",
    "\n",
    "# Load preprocessed data\n",
    "aug_data = load_data_pickle(get_save_path())\n",
    "total_X_test = aug_data['total_X_test']\n",
    "total_y_test = aug_data['total_y_test']\n",
    "total_X_train = aug_data['total_X_train']\n",
    "total_y_train = aug_data['total_y_train']\n",
    "total_X_val = aug_data['total_X_val']\n",
    "total_y_val = aug_data['total_y_val']\n",
    "total_X_train = np.transpose(total_X_train, (0, 2, 1))\n",
    "total_X_val = np.transpose(total_X_val, (0, 2, 1))\n",
    "total_X_test = np.transpose(total_X_test, (0, 2, 1))\n",
    "print(total_X_train.shape)\n",
    "print(total_y_train.shape)\n",
    "print(total_X_test.shape)\n",
    "print(total_y_test.shape)\n",
    "print(total_X_val.shape)\n",
    "print(total_y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11844, 100, 22)\n",
      "(11844, 4)\n",
      "(3101, 100, 22)\n",
      "(3101, 4)\n",
      "(2961, 100, 22)\n",
      "(2961, 4)\n"
     ]
    }
   ],
   "source": [
    "#total_X_train, total_y_train = shuffle(total_X_train, total_y_train, random_state=random.randint(1,1000))\n",
    "#total_X_val, total_y_val = shuffle(total_X_val, total_y_val, random_state=random.randint(1,1000))\n",
    "# total_X_test, total_y_test = shuffle(total_X_test, total_y_test, random_state=random.randint(1,1000))\n",
    "total_X_train = np.transpose(total_X_train, (0, 2, 1))\n",
    "total_X_val = np.transpose(total_X_val, (0, 2, 1))\n",
    "total_X_test = np.transpose(total_X_test, (0, 2, 1))\n",
    "print(total_X_train.shape)\n",
    "print(total_y_train.shape)\n",
    "print(total_X_test.shape)\n",
    "print(total_y_test.shape)\n",
    "print(total_X_val.shape)\n",
    "print(total_y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    # Network\n",
    "    'num_inputs': total_X_train.shape[0],\n",
    "    'input_shape': (total_X_train.shape[1],total_X_train.shape[2],1),\n",
    "    'epochs': 50,\n",
    "    'dropout': 0.3,\n",
    "    'batch_size': 320,\n",
    "    'l2': 0.01,\n",
    "    'lr': 0.001\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_1 (GRU)                  (None, 100, 22)           2970      \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 91, 22)            4862      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2002)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2002)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 8012      \n",
      "=================================================================\n",
      "Total params: 15,844\n",
      "Trainable params: 15,844\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model compiled.\n",
      "Train on 11844 samples, validate on 2961 samples\n",
      "Epoch 1/50\n",
      "11844/11844 [==============================] - 2s 153us/step - loss: 1.4064 - accuracy: 0.3934 - val_loss: 1.3181 - val_accuracy: 0.4282\n",
      "Epoch 2/50\n",
      "11844/11844 [==============================] - 2s 127us/step - loss: 1.0714 - accuracy: 0.5464 - val_loss: 1.2641 - val_accuracy: 0.4478\n",
      "Epoch 3/50\n",
      "11844/11844 [==============================] - 2s 129us/step - loss: 0.9556 - accuracy: 0.6040 - val_loss: 1.2289 - val_accuracy: 0.4715\n",
      "Epoch 4/50\n",
      "11844/11844 [==============================] - 1s 126us/step - loss: 0.8608 - accuracy: 0.6486 - val_loss: 1.1930 - val_accuracy: 0.4934\n",
      "Epoch 5/50\n",
      "11844/11844 [==============================] - 1s 126us/step - loss: 0.8054 - accuracy: 0.6766 - val_loss: 1.2084 - val_accuracy: 0.4951\n",
      "Epoch 6/50\n",
      "11844/11844 [==============================] - 2s 127us/step - loss: 0.7355 - accuracy: 0.7073 - val_loss: 1.1951 - val_accuracy: 0.5073\n",
      "Epoch 7/50\n",
      "11844/11844 [==============================] - 1s 126us/step - loss: 0.6810 - accuracy: 0.7330 - val_loss: 1.2163 - val_accuracy: 0.5103\n",
      "Epoch 8/50\n",
      "11844/11844 [==============================] - 2s 127us/step - loss: 0.6579 - accuracy: 0.7397 - val_loss: 1.2880 - val_accuracy: 0.4995\n",
      "Epoch 9/50\n",
      "11844/11844 [==============================] - 2s 129us/step - loss: 0.6670 - accuracy: 0.7404 - val_loss: 1.2400 - val_accuracy: 0.5103\n",
      "Epoch 10/50\n",
      "11844/11844 [==============================] - 2s 128us/step - loss: 0.6060 - accuracy: 0.7629 - val_loss: 1.2694 - val_accuracy: 0.5123\n",
      "Epoch 11/50\n",
      "11844/11844 [==============================] - 2s 127us/step - loss: 0.5692 - accuracy: 0.7799 - val_loss: 1.2525 - val_accuracy: 0.5238\n",
      "Epoch 12/50\n",
      "11844/11844 [==============================] - 2s 130us/step - loss: 0.5320 - accuracy: 0.7929 - val_loss: 1.3082 - val_accuracy: 0.5083\n",
      "Epoch 13/50\n",
      "11844/11844 [==============================] - 2s 131us/step - loss: 0.5339 - accuracy: 0.7942 - val_loss: 1.2397 - val_accuracy: 0.5292\n",
      "Epoch 14/50\n",
      "11844/11844 [==============================] - 2s 131us/step - loss: 0.4752 - accuracy: 0.8172 - val_loss: 1.2666 - val_accuracy: 0.5255\n",
      "Epoch 15/50\n",
      "11844/11844 [==============================] - 2s 129us/step - loss: 0.4782 - accuracy: 0.8149 - val_loss: 1.2806 - val_accuracy: 0.5265\n",
      "Epoch 16/50\n",
      "11844/11844 [==============================] - 2s 133us/step - loss: 0.4656 - accuracy: 0.8223 - val_loss: 1.3215 - val_accuracy: 0.5299\n",
      "Epoch 17/50\n",
      "11844/11844 [==============================] - 2s 129us/step - loss: 0.4650 - accuracy: 0.8186 - val_loss: 1.3294 - val_accuracy: 0.5248\n",
      "Epoch 18/50\n",
      "11844/11844 [==============================] - 2s 128us/step - loss: 0.4147 - accuracy: 0.8430 - val_loss: 1.3099 - val_accuracy: 0.5407\n",
      "Epoch 19/50\n",
      "11844/11844 [==============================] - 2s 128us/step - loss: 0.4075 - accuracy: 0.8448 - val_loss: 1.3467 - val_accuracy: 0.5360\n",
      "Epoch 20/50\n",
      "11844/11844 [==============================] - 2s 129us/step - loss: 0.3832 - accuracy: 0.8541 - val_loss: 1.3564 - val_accuracy: 0.5292\n",
      "Epoch 21/50\n",
      "11844/11844 [==============================] - 2s 128us/step - loss: 0.3592 - accuracy: 0.8645 - val_loss: 1.3548 - val_accuracy: 0.5387\n",
      "Epoch 22/50\n",
      "11844/11844 [==============================] - 2s 131us/step - loss: 0.3581 - accuracy: 0.8666 - val_loss: 1.4514 - val_accuracy: 0.5225\n",
      "Epoch 23/50\n",
      "11844/11844 [==============================] - 2s 132us/step - loss: 0.4484 - accuracy: 0.8297 - val_loss: 1.4100 - val_accuracy: 0.5255\n",
      "Epoch 24/50\n",
      "11844/11844 [==============================] - 2s 131us/step - loss: 0.3485 - accuracy: 0.8694 - val_loss: 1.4125 - val_accuracy: 0.5377\n",
      "Epoch 25/50\n",
      "11844/11844 [==============================] - 2s 130us/step - loss: 0.3064 - accuracy: 0.8880 - val_loss: 1.4175 - val_accuracy: 0.5407\n",
      "Epoch 26/50\n",
      "11844/11844 [==============================] - 2s 130us/step - loss: 0.2949 - accuracy: 0.8921 - val_loss: 1.3938 - val_accuracy: 0.5454\n",
      "Epoch 27/50\n",
      "11844/11844 [==============================] - 2s 131us/step - loss: 0.3296 - accuracy: 0.8750 - val_loss: 1.4578 - val_accuracy: 0.5292\n",
      "Epoch 28/50\n",
      "11844/11844 [==============================] - 2s 130us/step - loss: 0.3041 - accuracy: 0.8823 - val_loss: 1.4255 - val_accuracy: 0.5458\n",
      "Epoch 29/50\n",
      "11844/11844 [==============================] - 2s 132us/step - loss: 0.2751 - accuracy: 0.8978 - val_loss: 1.4792 - val_accuracy: 0.5333\n",
      "Epoch 30/50\n",
      "11844/11844 [==============================] - 2s 132us/step - loss: 0.2604 - accuracy: 0.9041 - val_loss: 1.4462 - val_accuracy: 0.5444\n",
      "Epoch 31/50\n",
      "11844/11844 [==============================] - 2s 137us/step - loss: 0.2648 - accuracy: 0.9010 - val_loss: 1.5066 - val_accuracy: 0.5296\n",
      "Epoch 32/50\n",
      "11844/11844 [==============================] - 2s 134us/step - loss: 0.3375 - accuracy: 0.8713 - val_loss: 1.5439 - val_accuracy: 0.5329\n",
      "Epoch 33/50\n",
      "11844/11844 [==============================] - 2s 135us/step - loss: 0.2724 - accuracy: 0.8966 - val_loss: 1.4881 - val_accuracy: 0.5468\n",
      "Epoch 34/50\n",
      "11844/11844 [==============================] - 2s 130us/step - loss: 0.2481 - accuracy: 0.9093 - val_loss: 1.5217 - val_accuracy: 0.5417\n",
      "Epoch 35/50\n",
      "11844/11844 [==============================] - 2s 129us/step - loss: 0.2444 - accuracy: 0.9075 - val_loss: 1.5169 - val_accuracy: 0.5400\n",
      "Epoch 36/50\n",
      "11844/11844 [==============================] - 2s 130us/step - loss: 0.2638 - accuracy: 0.9000 - val_loss: 1.5705 - val_accuracy: 0.5356\n",
      "Epoch 37/50\n",
      "11844/11844 [==============================] - 2s 130us/step - loss: 0.2316 - accuracy: 0.9131 - val_loss: 1.5181 - val_accuracy: 0.5495\n",
      "Epoch 38/50\n",
      "11844/11844 [==============================] - 2s 130us/step - loss: 0.2143 - accuracy: 0.9190 - val_loss: 1.5580 - val_accuracy: 0.5485\n",
      "Epoch 39/50\n",
      "11844/11844 [==============================] - 2s 130us/step - loss: 0.2195 - accuracy: 0.9186 - val_loss: 1.5536 - val_accuracy: 0.5562\n",
      "Epoch 40/50\n",
      "11844/11844 [==============================] - 2s 131us/step - loss: 0.2059 - accuracy: 0.9237 - val_loss: 1.5653 - val_accuracy: 0.5630\n",
      "Epoch 41/50\n",
      "11844/11844 [==============================] - 2s 129us/step - loss: 0.2359 - accuracy: 0.9089 - val_loss: 1.5833 - val_accuracy: 0.5525\n",
      "Epoch 42/50\n",
      "11844/11844 [==============================] - 2s 129us/step - loss: 0.2141 - accuracy: 0.9202 - val_loss: 1.6224 - val_accuracy: 0.5545\n",
      "Epoch 43/50\n",
      "11844/11844 [==============================] - 2s 130us/step - loss: 0.2189 - accuracy: 0.9160 - val_loss: 1.5799 - val_accuracy: 0.5623\n",
      "Epoch 44/50\n",
      "11844/11844 [==============================] - 2s 130us/step - loss: 0.2103 - accuracy: 0.9215 - val_loss: 1.5985 - val_accuracy: 0.5714\n",
      "Epoch 45/50\n",
      "11844/11844 [==============================] - 2s 131us/step - loss: 0.1970 - accuracy: 0.9262 - val_loss: 1.5801 - val_accuracy: 0.5599\n",
      "Epoch 46/50\n",
      "11844/11844 [==============================] - 2s 130us/step - loss: 0.1810 - accuracy: 0.9336 - val_loss: 1.6134 - val_accuracy: 0.5620\n",
      "Epoch 47/50\n",
      "11844/11844 [==============================] - 2s 132us/step - loss: 0.1935 - accuracy: 0.9276 - val_loss: 1.6267 - val_accuracy: 0.5670\n",
      "Epoch 48/50\n",
      "11844/11844 [==============================] - 2s 130us/step - loss: 0.1810 - accuracy: 0.9322 - val_loss: 1.6806 - val_accuracy: 0.5508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50\n",
      "11844/11844 [==============================] - 2s 130us/step - loss: 0.2187 - accuracy: 0.9165 - val_loss: 1.6238 - val_accuracy: 0.5684\n",
      "Epoch 50/50\n",
      "11844/11844 [==============================] - 2s 130us/step - loss: 0.1726 - accuracy: 0.9341 - val_loss: 1.6584 - val_accuracy: 0.5772\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7ff0604eed68>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SimpleGRUConv = SimpleGRUConv()\n",
    "SimpleGRUConv.build_model(config)\n",
    "SimpleGRUConv.train(total_X_train, total_y_train, total_X_val, total_y_val, config, workpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3101/3101 [==============================] - 0s 130us/step\n",
      "Raw Acc result: 0.5994840264320374\n",
      "Majority Vote result: 0.6162528216704289\n",
      "Old model exists. Comparing performance.\n",
      "New model is worse than the old one. Will not update the old model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = [SimpleGRUConv.predict(total_X_test[i::total_X_test.shape[0]], 0) for i in range(total_X_test.shape[0])]\n",
    "majority_pred = []\n",
    "for pred in preds:\n",
    "    arg_maxes = [np.argmax(p) for p in pred]\n",
    "    votes = np.bincount(arg_maxes)\n",
    "    out = np.ndarray(shape=(4,), buffer=np.zeros(4), dtype=int)\n",
    "    out[votes.argmax()] = 1\n",
    "    majority_pred.append(out)\n",
    "result = [(a == b).all() for a, b in zip(majority_pred, total_y_test[0:total_X_test.shape[0]])]\n",
    "raw = SimpleGRUConv.evaluate(total_X_test, total_y_test)\n",
    "print(\"Raw Acc result: {}\".format(raw[1]))\n",
    "print(\"Majority Vote result: {}\".format(np.mean(result)))\n",
    "filepath = join(save_path, 'SimpleGRUConv.pickle')\n",
    "replace_model_if_better(filepath, np.mean(result), SimpleGRUConv, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3101/3101 [==============================] - 0s 145us/step\n",
      "Raw Acc result: 0.5994840264320374\n",
      "Majority Vote result: 0.6162528216704289\n",
      "Old model exists. Comparing performance.\n",
      "New model is worse than the old one. Will not update the old model\n"
     ]
    }
   ],
   "source": [
    "model_path = join(workpath, '*.hdf5')\n",
    "list_of_files = glob.glob(model_path) # * means all if need specific format then *.csv\n",
    "latest_file = max(list_of_files, key=getctime)\n",
    "model_val = load_model(latest_file)\n",
    "preds = [model_val.predict(total_X_test[i::total_X_test.shape[0]], verbose=0) for i in range(total_X_test.shape[0])]\n",
    "majority_pred = []\n",
    "for pred in preds:\n",
    "    arg_maxes = [np.argmax(p) for p in pred]\n",
    "    votes = np.bincount(arg_maxes)\n",
    "    out = np.ndarray(shape=(4,), buffer=np.zeros(4), dtype=int)\n",
    "    out[votes.argmax()] = 1\n",
    "    majority_pred.append(out)\n",
    "result = [(a == b).all() for a, b in zip(majority_pred, total_y_test[0:total_X_test.shape[0]])]\n",
    "raw = model_val.evaluate(total_X_test, total_y_test)\n",
    "print(\"Raw Acc result: {}\".format(raw[1]))\n",
    "print(\"Majority Vote result: {}\".format(np.mean(result)))\n",
    "filepath = join(save_path, 'best_val', 'SimpleGRUConv_val.pickle')\n",
    "replaced = replace_model_if_better(filepath, np.mean(result), model_val, config)\n",
    "rmtree(workpath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
