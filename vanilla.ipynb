{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data pickle...\n",
      "Data pickle loaded.\n",
      "(11844, 100, 22)\n",
      "(11844, 4)\n",
      "(3101, 100, 22)\n",
      "(3101, 4)\n",
      "(2961, 100, 22)\n",
      "(2961, 4)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from model import *\n",
    "import datetime\n",
    "from utils import *\n",
    "from preprocessing import *\n",
    "import random\n",
    "import glob\n",
    "from os.path import join, getctime, basename\n",
    "from load_data import load_data\n",
    "from save_model import replace_model_if_better\n",
    "from keras.models import load_model\n",
    "from shutil import rmtree\n",
    "\n",
    "## Loading Preprocessed Data\n",
    "\n",
    "# Create result folders \n",
    "save_path = join(get_save_path(), 'VanillaRNN')\n",
    "new_path = join(save_path, 'best_val')\n",
    "time = str(datetime.datetime.now()).replace(' ', '_')\n",
    "workpath = join(save_path, time)\n",
    "ensure_dir(new_path)\n",
    "ensure_dir(workpath)\n",
    "ensure_dir(save_path)\n",
    "\n",
    "# Load preprocessed data\n",
    "aug_data = load_data_pickle(get_save_path())\n",
    "total_X_test = aug_data['total_X_test']\n",
    "total_y_test = aug_data['total_y_test']\n",
    "total_X_train = aug_data['total_X_train']\n",
    "total_y_train = aug_data['total_y_train']\n",
    "total_X_val = aug_data['total_X_val']\n",
    "total_y_val = aug_data['total_y_val']\n",
    "total_X_train = np.transpose(total_X_train, (0, 2, 1))\n",
    "total_X_val = np.transpose(total_X_val, (0, 2, 1))\n",
    "total_X_test = np.transpose(total_X_test, (0, 2, 1))\n",
    "print(total_X_train.shape)\n",
    "print(total_y_train.shape)\n",
    "print(total_X_test.shape)\n",
    "print(total_y_test.shape)\n",
    "print(total_X_val.shape)\n",
    "print(total_y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    # Network\n",
    "    'num_inputs': total_X_train.shape[0],\n",
    "    'input_shape': (total_X_train.shape[1],total_X_train.shape[2],1),\n",
    "    'epochs': 50,\n",
    "    'dropout': 0.5,\n",
    "    'batch_size': 512,\n",
    "    'l2': 0.05,\n",
    "    'LSTM': False,\n",
    "    'lr': 0.001\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_1 (GRU)                  (None, 100, 22)           2970      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2200)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2200)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 8804      \n",
      "=================================================================\n",
      "Total params: 11,774\n",
      "Trainable params: 11,774\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model compiled.\n",
      "Train on 11844 samples, validate on 2961 samples\n",
      "Epoch 1/50\n",
      "11844/11844 [==============================] - 1s 117us/step - loss: 1.3631 - accuracy: 0.3311 - val_loss: 1.3303 - val_accuracy: 0.3722\n",
      "Epoch 2/50\n",
      "11844/11844 [==============================] - 1s 90us/step - loss: 1.2677 - accuracy: 0.4503 - val_loss: 1.2927 - val_accuracy: 0.4151\n",
      "Epoch 3/50\n",
      "11844/11844 [==============================] - 1s 92us/step - loss: 1.2035 - accuracy: 0.5338 - val_loss: 1.2600 - val_accuracy: 0.4745\n",
      "Epoch 4/50\n",
      "11844/11844 [==============================] - 1s 92us/step - loss: 1.1591 - accuracy: 0.5817 - val_loss: 1.2388 - val_accuracy: 0.4883\n",
      "Epoch 5/50\n",
      "11844/11844 [==============================] - 1s 91us/step - loss: 1.1241 - accuracy: 0.6201 - val_loss: 1.2198 - val_accuracy: 0.5039\n",
      "Epoch 6/50\n",
      "11844/11844 [==============================] - 1s 92us/step - loss: 1.0973 - accuracy: 0.6518 - val_loss: 1.2048 - val_accuracy: 0.5252\n",
      "Epoch 7/50\n",
      "11844/11844 [==============================] - 1s 91us/step - loss: 1.0737 - accuracy: 0.6743 - val_loss: 1.2009 - val_accuracy: 0.5218\n",
      "Epoch 8/50\n",
      "11844/11844 [==============================] - 1s 90us/step - loss: 1.0563 - accuracy: 0.6931 - val_loss: 1.1945 - val_accuracy: 0.5312\n",
      "Epoch 9/50\n",
      "11844/11844 [==============================] - 1s 90us/step - loss: 1.0399 - accuracy: 0.7137 - val_loss: 1.1885 - val_accuracy: 0.5414\n",
      "Epoch 10/50\n",
      "11844/11844 [==============================] - 1s 90us/step - loss: 1.0282 - accuracy: 0.7222 - val_loss: 1.1856 - val_accuracy: 0.5363\n",
      "Epoch 11/50\n",
      "11844/11844 [==============================] - 1s 91us/step - loss: 1.0218 - accuracy: 0.7280 - val_loss: 1.1785 - val_accuracy: 0.5495\n",
      "Epoch 12/50\n",
      "11844/11844 [==============================] - 1s 90us/step - loss: 1.0118 - accuracy: 0.7412 - val_loss: 1.1800 - val_accuracy: 0.5427\n",
      "Epoch 13/50\n",
      "11844/11844 [==============================] - 1s 91us/step - loss: 1.0037 - accuracy: 0.7476 - val_loss: 1.1705 - val_accuracy: 0.5552\n",
      "Epoch 14/50\n",
      "11844/11844 [==============================] - 1s 92us/step - loss: 0.9955 - accuracy: 0.7579 - val_loss: 1.1674 - val_accuracy: 0.5620\n",
      "Epoch 15/50\n",
      "11844/11844 [==============================] - 1s 92us/step - loss: 0.9907 - accuracy: 0.7587 - val_loss: 1.1594 - val_accuracy: 0.5687\n",
      "Epoch 16/50\n",
      "11844/11844 [==============================] - 1s 90us/step - loss: 0.9826 - accuracy: 0.7697 - val_loss: 1.1600 - val_accuracy: 0.5718\n",
      "Epoch 17/50\n",
      "11844/11844 [==============================] - 1s 90us/step - loss: 0.9761 - accuracy: 0.7768 - val_loss: 1.1594 - val_accuracy: 0.5738\n",
      "Epoch 18/50\n",
      "11844/11844 [==============================] - 1s 91us/step - loss: 0.9718 - accuracy: 0.7795 - val_loss: 1.1516 - val_accuracy: 0.5775\n",
      "Epoch 19/50\n",
      "11844/11844 [==============================] - 1s 93us/step - loss: 0.9679 - accuracy: 0.7837 - val_loss: 1.1506 - val_accuracy: 0.5758\n",
      "Epoch 20/50\n",
      "11844/11844 [==============================] - 1s 92us/step - loss: 0.9623 - accuracy: 0.7880 - val_loss: 1.1502 - val_accuracy: 0.5782\n",
      "Epoch 21/50\n",
      "11844/11844 [==============================] - 1s 91us/step - loss: 0.9573 - accuracy: 0.7972 - val_loss: 1.1519 - val_accuracy: 0.5731\n",
      "Epoch 22/50\n",
      "11844/11844 [==============================] - 1s 91us/step - loss: 0.9517 - accuracy: 0.8007 - val_loss: 1.1461 - val_accuracy: 0.5836\n",
      "Epoch 23/50\n",
      "11844/11844 [==============================] - 1s 91us/step - loss: 0.9509 - accuracy: 0.8018 - val_loss: 1.1475 - val_accuracy: 0.5816\n",
      "Epoch 24/50\n",
      "11844/11844 [==============================] - 1s 91us/step - loss: 0.9488 - accuracy: 0.8014 - val_loss: 1.1478 - val_accuracy: 0.5758\n",
      "Epoch 25/50\n",
      "11844/11844 [==============================] - 1s 92us/step - loss: 0.9427 - accuracy: 0.8099 - val_loss: 1.1408 - val_accuracy: 0.5860\n",
      "Epoch 26/50\n",
      "11844/11844 [==============================] - 1s 91us/step - loss: 0.9419 - accuracy: 0.8098 - val_loss: 1.1422 - val_accuracy: 0.5887\n",
      "Epoch 27/50\n",
      "11844/11844 [==============================] - 1s 92us/step - loss: 0.9381 - accuracy: 0.8143 - val_loss: 1.1402 - val_accuracy: 0.5924\n",
      "Epoch 28/50\n",
      "11844/11844 [==============================] - 1s 92us/step - loss: 0.9374 - accuracy: 0.8117 - val_loss: 1.1341 - val_accuracy: 0.5954\n",
      "Epoch 29/50\n",
      "11844/11844 [==============================] - 1s 91us/step - loss: 0.9345 - accuracy: 0.8181 - val_loss: 1.1447 - val_accuracy: 0.5819\n",
      "Epoch 30/50\n",
      "11844/11844 [==============================] - 1s 92us/step - loss: 0.9299 - accuracy: 0.8217 - val_loss: 1.1405 - val_accuracy: 0.5849\n",
      "Epoch 31/50\n",
      "11844/11844 [==============================] - 1s 92us/step - loss: 0.9256 - accuracy: 0.8257 - val_loss: 1.1333 - val_accuracy: 0.5937\n",
      "Epoch 32/50\n",
      "11844/11844 [==============================] - 1s 92us/step - loss: 0.9259 - accuracy: 0.8248 - val_loss: 1.1338 - val_accuracy: 0.5968\n",
      "Epoch 33/50\n",
      "11844/11844 [==============================] - 1s 93us/step - loss: 0.9241 - accuracy: 0.8259 - val_loss: 1.1344 - val_accuracy: 0.5957\n",
      "Epoch 34/50\n",
      "11844/11844 [==============================] - 1s 90us/step - loss: 0.9207 - accuracy: 0.8300 - val_loss: 1.1362 - val_accuracy: 0.5903\n",
      "Epoch 35/50\n",
      "11844/11844 [==============================] - 1s 90us/step - loss: 0.9209 - accuracy: 0.8323 - val_loss: 1.1407 - val_accuracy: 0.5843\n",
      "Epoch 36/50\n",
      "11844/11844 [==============================] - 1s 91us/step - loss: 0.9113 - accuracy: 0.8410 - val_loss: 1.1317 - val_accuracy: 0.5957\n",
      "Epoch 37/50\n",
      "11844/11844 [==============================] - 1s 91us/step - loss: 0.9144 - accuracy: 0.8343 - val_loss: 1.1323 - val_accuracy: 0.5964\n",
      "Epoch 38/50\n",
      "11844/11844 [==============================] - 1s 91us/step - loss: 0.9145 - accuracy: 0.8358 - val_loss: 1.1272 - val_accuracy: 0.5981\n",
      "Epoch 39/50\n",
      "11844/11844 [==============================] - 1s 91us/step - loss: 0.9111 - accuracy: 0.8364 - val_loss: 1.1315 - val_accuracy: 0.5934\n",
      "Epoch 40/50\n",
      "11844/11844 [==============================] - 1s 92us/step - loss: 0.9103 - accuracy: 0.8407 - val_loss: 1.1261 - val_accuracy: 0.6028\n",
      "Epoch 41/50\n",
      "11844/11844 [==============================] - 1s 91us/step - loss: 0.9074 - accuracy: 0.8425 - val_loss: 1.1301 - val_accuracy: 0.6008\n",
      "Epoch 42/50\n",
      "11844/11844 [==============================] - 1s 93us/step - loss: 0.9027 - accuracy: 0.8498 - val_loss: 1.1271 - val_accuracy: 0.6011\n",
      "Epoch 43/50\n",
      "11844/11844 [==============================] - 1s 92us/step - loss: 0.9029 - accuracy: 0.8464 - val_loss: 1.1245 - val_accuracy: 0.6069\n",
      "Epoch 44/50\n",
      "11844/11844 [==============================] - 1s 91us/step - loss: 0.9038 - accuracy: 0.8463 - val_loss: 1.1233 - val_accuracy: 0.6025\n",
      "Epoch 45/50\n",
      "11844/11844 [==============================] - 1s 92us/step - loss: 0.9005 - accuracy: 0.8492 - val_loss: 1.1261 - val_accuracy: 0.6032\n",
      "Epoch 46/50\n",
      "11844/11844 [==============================] - 1s 91us/step - loss: 0.8997 - accuracy: 0.8506 - val_loss: 1.1214 - val_accuracy: 0.6099\n",
      "Epoch 47/50\n",
      "11844/11844 [==============================] - 1s 91us/step - loss: 0.8977 - accuracy: 0.8543 - val_loss: 1.1209 - val_accuracy: 0.6055\n",
      "Epoch 48/50\n",
      "11844/11844 [==============================] - 1s 91us/step - loss: 0.8969 - accuracy: 0.8545 - val_loss: 1.1204 - val_accuracy: 0.6096\n",
      "Epoch 49/50\n",
      "11844/11844 [==============================] - 1s 92us/step - loss: 0.8970 - accuracy: 0.8519 - val_loss: 1.1229 - val_accuracy: 0.6035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50\n",
      "11844/11844 [==============================] - 1s 91us/step - loss: 0.8933 - accuracy: 0.8565 - val_loss: 1.1143 - val_accuracy: 0.6174\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f4a40257c88>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VanillaRNN1 = VanillaRNN()\n",
    "VanillaRNN1.build_model(config)\n",
    "VanillaRNN1.train(total_X_train, total_y_train, total_X_val, total_y_val, config, workpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3101/3101 [==============================] - 0s 118us/step\n",
      "Raw Acc result: 0.6336665749549866\n",
      "Majority Vote result: 0.6501128668171557\n",
      "No existing model in specified path. Saving the new model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Majority Voting\n",
    "preds = [VanillaRNN1.predict(total_X_test[i::443], 0) for i in range(443)]\n",
    "majority_pred = []\n",
    "for pred in preds:\n",
    "    arg_maxes = [np.argmax(p) for p in pred]\n",
    "    votes = np.bincount(arg_maxes)\n",
    "    out = np.ndarray(shape=(4,), buffer=np.zeros(4), dtype=int)\n",
    "    out[votes.argmax()] = 1\n",
    "    majority_pred.append(out)\n",
    "result = [(a == b).all() for a, b in zip(majority_pred, total_y_test[0:443])]\n",
    "raw = VanillaRNN1.evaluate(total_X_test, total_y_test)\n",
    "print(\"Raw Acc result: {}\".format(raw[1]))\n",
    "print(\"Majority Vote result: {}\".format(np.mean(result)))\n",
    "filepath = join(save_path, 'VanillaGRU.pickle')\n",
    "replace_model_if_better(filepath, np.mean(result), VanillaRNN, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3101/3101 [==============================] - 0s 136us/step\n",
      "Raw Acc result: 0.6336665749549866\n",
      "Majority Vote result: 0.6501128668171557\n",
      "No existing model in specified path. Saving the new model\n"
     ]
    }
   ],
   "source": [
    "# Load the checkpointed model with highest val acc and perform majority voting\n",
    "model_path = join(workpath, '*.hdf5')\n",
    "list_of_files = glob.glob(model_path)\n",
    "latest_file = max(list_of_files, key=getctime)\n",
    "model_val = load_model(latest_file)\n",
    "preds = [model_val.predict(total_X_test[i::443], verbose=0) \n",
    "         for i in range(443)]\n",
    "majority_pred = []\n",
    "for pred in preds:\n",
    "    arg_maxes = [np.argmax(p) for p in pred]\n",
    "    votes = np.bincount(arg_maxes)\n",
    "    out = np.ndarray(shape=(4,), buffer=np.zeros(4), dtype=int)\n",
    "    out[votes.argmax()] = 1\n",
    "    majority_pred.append(out)\n",
    "result = [(a == b).all() for a, b in zip(majority_pred, total_y_test[0:443])]\n",
    "raw = model_val.evaluate(total_X_test, total_y_test)\n",
    "print(\"Raw Acc result: {}\".format(raw[1]))\n",
    "print(\"Majority Vote result: {}\".format(np.mean(result)))\n",
    "filepath = join(save_path, 'best_val', 'VanillaRNN_val.pickle')\n",
    "replaced = replace_model_if_better(filepath, np.mean(result), model_val, config)\n",
    "rmtree(workpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    # Network\n",
    "    'num_inputs': total_X_train.shape[0],\n",
    "    'input_shape': (total_X_train.shape[1],total_X_train.shape[2],1),\n",
    "    'epochs': 50,\n",
    "    'dropout': 0.5,\n",
    "    'batch_size': 512,\n",
    "    'l2': 0.05,\n",
    "    'LSTM': True,\n",
    "    'lr': 0.001\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 100, 22)           3960      \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2200)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 2200)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 8804      \n",
      "=================================================================\n",
      "Total params: 12,764\n",
      "Trainable params: 12,764\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model compiled.\n",
      "Train on 11844 samples, validate on 2961 samples\n",
      "Epoch 1/50\n",
      "11844/11844 [==============================] - 1s 118us/step - loss: 1.3600 - accuracy: 0.3266 - val_loss: 1.3418 - val_accuracy: 0.3600\n",
      "Epoch 2/50\n",
      "11844/11844 [==============================] - 1s 101us/step - loss: 1.2772 - accuracy: 0.4605 - val_loss: 1.2998 - val_accuracy: 0.4316\n",
      "Epoch 3/50\n",
      "11844/11844 [==============================] - 1s 100us/step - loss: 1.2181 - accuracy: 0.5349 - val_loss: 1.2733 - val_accuracy: 0.4478\n",
      "Epoch 4/50\n",
      "11844/11844 [==============================] - 1s 101us/step - loss: 1.1753 - accuracy: 0.5844 - val_loss: 1.2561 - val_accuracy: 0.4647\n",
      "Epoch 5/50\n",
      "11844/11844 [==============================] - 1s 100us/step - loss: 1.1416 - accuracy: 0.6162 - val_loss: 1.2426 - val_accuracy: 0.4772\n",
      "Epoch 6/50\n",
      "11844/11844 [==============================] - 1s 100us/step - loss: 1.1165 - accuracy: 0.6437 - val_loss: 1.2389 - val_accuracy: 0.4681\n",
      "Epoch 7/50\n",
      "11844/11844 [==============================] - 1s 99us/step - loss: 1.0925 - accuracy: 0.6716 - val_loss: 1.2297 - val_accuracy: 0.4867\n",
      "Epoch 8/50\n",
      "11844/11844 [==============================] - 1s 100us/step - loss: 1.0758 - accuracy: 0.6845 - val_loss: 1.2253 - val_accuracy: 0.4840\n",
      "Epoch 9/50\n",
      "11844/11844 [==============================] - 1s 100us/step - loss: 1.0600 - accuracy: 0.7025 - val_loss: 1.2212 - val_accuracy: 0.4911\n",
      "Epoch 10/50\n",
      "11844/11844 [==============================] - 1s 101us/step - loss: 1.0454 - accuracy: 0.7161 - val_loss: 1.2192 - val_accuracy: 0.4948\n",
      "Epoch 11/50\n",
      "11844/11844 [==============================] - 1s 102us/step - loss: 1.0327 - accuracy: 0.7275 - val_loss: 1.2078 - val_accuracy: 0.5106\n",
      "Epoch 12/50\n",
      "11844/11844 [==============================] - 1s 101us/step - loss: 1.0221 - accuracy: 0.7379 - val_loss: 1.2082 - val_accuracy: 0.5093\n",
      "Epoch 13/50\n",
      "11844/11844 [==============================] - 1s 102us/step - loss: 1.0136 - accuracy: 0.7448 - val_loss: 1.2039 - val_accuracy: 0.5252\n",
      "Epoch 14/50\n",
      "11844/11844 [==============================] - 1s 101us/step - loss: 1.0037 - accuracy: 0.7586 - val_loss: 1.2017 - val_accuracy: 0.5157\n",
      "Epoch 15/50\n",
      "11844/11844 [==============================] - 1s 103us/step - loss: 0.9922 - accuracy: 0.7703 - val_loss: 1.1956 - val_accuracy: 0.5323\n",
      "Epoch 16/50\n",
      "11844/11844 [==============================] - 1s 101us/step - loss: 0.9929 - accuracy: 0.7638 - val_loss: 1.1944 - val_accuracy: 0.5323\n",
      "Epoch 17/50\n",
      "11844/11844 [==============================] - 1s 102us/step - loss: 0.9824 - accuracy: 0.7775 - val_loss: 1.1886 - val_accuracy: 0.5380\n",
      "Epoch 18/50\n",
      "11844/11844 [==============================] - 1s 102us/step - loss: 0.9777 - accuracy: 0.7830 - val_loss: 1.1926 - val_accuracy: 0.5343\n",
      "Epoch 19/50\n",
      "11844/11844 [==============================] - 1s 102us/step - loss: 0.9733 - accuracy: 0.7837 - val_loss: 1.1884 - val_accuracy: 0.5353\n",
      "Epoch 20/50\n",
      "11844/11844 [==============================] - 1s 103us/step - loss: 0.9668 - accuracy: 0.7906 - val_loss: 1.1833 - val_accuracy: 0.5393\n",
      "Epoch 21/50\n",
      "11844/11844 [==============================] - 1s 100us/step - loss: 0.9648 - accuracy: 0.7942 - val_loss: 1.1840 - val_accuracy: 0.5417\n",
      "Epoch 22/50\n",
      "11844/11844 [==============================] - 1s 101us/step - loss: 0.9587 - accuracy: 0.7995 - val_loss: 1.1782 - val_accuracy: 0.5542\n",
      "Epoch 23/50\n",
      "11844/11844 [==============================] - 1s 103us/step - loss: 0.9540 - accuracy: 0.8036 - val_loss: 1.1726 - val_accuracy: 0.5572\n",
      "Epoch 24/50\n",
      "11844/11844 [==============================] - 1s 102us/step - loss: 0.9487 - accuracy: 0.8091 - val_loss: 1.1772 - val_accuracy: 0.5464\n",
      "Epoch 25/50\n",
      "11844/11844 [==============================] - 1s 103us/step - loss: 0.9519 - accuracy: 0.8048 - val_loss: 1.1776 - val_accuracy: 0.5502\n",
      "Epoch 26/50\n",
      "11844/11844 [==============================] - 1s 103us/step - loss: 0.9429 - accuracy: 0.8140 - val_loss: 1.1737 - val_accuracy: 0.5515\n",
      "Epoch 27/50\n",
      "11844/11844 [==============================] - 1s 103us/step - loss: 0.9384 - accuracy: 0.8170 - val_loss: 1.1761 - val_accuracy: 0.5525\n",
      "Epoch 28/50\n",
      "11844/11844 [==============================] - 1s 101us/step - loss: 0.9349 - accuracy: 0.8219 - val_loss: 1.1696 - val_accuracy: 0.5613\n",
      "Epoch 29/50\n",
      "11844/11844 [==============================] - 1s 103us/step - loss: 0.9341 - accuracy: 0.8210 - val_loss: 1.1726 - val_accuracy: 0.5603\n",
      "Epoch 30/50\n",
      "11844/11844 [==============================] - 1s 103us/step - loss: 0.9328 - accuracy: 0.8229 - val_loss: 1.1730 - val_accuracy: 0.5475\n",
      "Epoch 31/50\n",
      "11844/11844 [==============================] - 1s 102us/step - loss: 0.9295 - accuracy: 0.8242 - val_loss: 1.1659 - val_accuracy: 0.5653\n",
      "Epoch 32/50\n",
      "11844/11844 [==============================] - 1s 103us/step - loss: 0.9275 - accuracy: 0.8288 - val_loss: 1.1675 - val_accuracy: 0.5610\n",
      "Epoch 33/50\n",
      "11844/11844 [==============================] - 1s 101us/step - loss: 0.9232 - accuracy: 0.8312 - val_loss: 1.1662 - val_accuracy: 0.5620\n",
      "Epoch 34/50\n",
      "11844/11844 [==============================] - 1s 101us/step - loss: 0.9189 - accuracy: 0.8360 - val_loss: 1.1660 - val_accuracy: 0.5640\n",
      "Epoch 35/50\n",
      "11844/11844 [==============================] - 1s 103us/step - loss: 0.9184 - accuracy: 0.8360 - val_loss: 1.1655 - val_accuracy: 0.5616\n",
      "Epoch 36/50\n",
      "11844/11844 [==============================] - 1s 103us/step - loss: 0.9164 - accuracy: 0.8387 - val_loss: 1.1626 - val_accuracy: 0.5691\n",
      "Epoch 37/50\n",
      "11844/11844 [==============================] - 1s 102us/step - loss: 0.9126 - accuracy: 0.8423 - val_loss: 1.1591 - val_accuracy: 0.5684\n",
      "Epoch 38/50\n",
      "11844/11844 [==============================] - 1s 102us/step - loss: 0.9088 - accuracy: 0.8472 - val_loss: 1.1558 - val_accuracy: 0.5775\n",
      "Epoch 39/50\n",
      "11844/11844 [==============================] - 1s 104us/step - loss: 0.9075 - accuracy: 0.8451 - val_loss: 1.1566 - val_accuracy: 0.5775\n",
      "Epoch 40/50\n",
      "11844/11844 [==============================] - 1s 101us/step - loss: 0.9084 - accuracy: 0.8446 - val_loss: 1.1555 - val_accuracy: 0.5735\n",
      "Epoch 41/50\n",
      "11844/11844 [==============================] - 1s 101us/step - loss: 0.9067 - accuracy: 0.8461 - val_loss: 1.1593 - val_accuracy: 0.5704\n",
      "Epoch 42/50\n",
      "11844/11844 [==============================] - 1s 103us/step - loss: 0.9039 - accuracy: 0.8488 - val_loss: 1.1533 - val_accuracy: 0.5843\n",
      "Epoch 43/50\n",
      "11844/11844 [==============================] - 1s 102us/step - loss: 0.9045 - accuracy: 0.8495 - val_loss: 1.1516 - val_accuracy: 0.5782\n",
      "Epoch 44/50\n",
      "11844/11844 [==============================] - 1s 103us/step - loss: 0.9044 - accuracy: 0.8484 - val_loss: 1.1563 - val_accuracy: 0.5711\n",
      "Epoch 45/50\n",
      "11844/11844 [==============================] - 1s 102us/step - loss: 0.9025 - accuracy: 0.8493 - val_loss: 1.1515 - val_accuracy: 0.5735\n",
      "Epoch 46/50\n",
      "11844/11844 [==============================] - 1s 105us/step - loss: 0.8962 - accuracy: 0.8564 - val_loss: 1.1532 - val_accuracy: 0.5758\n",
      "Epoch 47/50\n",
      "11844/11844 [==============================] - 1s 103us/step - loss: 0.8975 - accuracy: 0.8547 - val_loss: 1.1531 - val_accuracy: 0.5711\n",
      "Epoch 48/50\n",
      "11844/11844 [==============================] - 1s 102us/step - loss: 0.8928 - accuracy: 0.8611 - val_loss: 1.1468 - val_accuracy: 0.5846\n",
      "Epoch 49/50\n",
      "11844/11844 [==============================] - 1s 101us/step - loss: 0.8931 - accuracy: 0.8592 - val_loss: 1.1482 - val_accuracy: 0.5826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50\n",
      "11844/11844 [==============================] - 1s 102us/step - loss: 0.8879 - accuracy: 0.8652 - val_loss: 1.1460 - val_accuracy: 0.5758\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f49c67bceb8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VanillaRNN2 = VanillaRNN()\n",
    "VanillaRNN2.build_model(config)\n",
    "VanillaRNN2.train(total_X_train, total_y_train, total_X_val, total_y_val, config, workpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3101/3101 [==============================] - 0s 117us/step\n",
      "Raw Acc result: 0.5707836151123047\n",
      "Majority Vote result: 0.5846501128668171\n",
      "No existing model in specified path. Saving the new model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Majority Voting\n",
    "preds = [VanillaRNN2.predict(total_X_test[i::443], 0) for i in range(443)]\n",
    "majority_pred = []\n",
    "for pred in preds:\n",
    "    arg_maxes = [np.argmax(p) for p in pred]\n",
    "    votes = np.bincount(arg_maxes)\n",
    "    out = np.ndarray(shape=(4,), buffer=np.zeros(4), dtype=int)\n",
    "    out[votes.argmax()] = 1\n",
    "    majority_pred.append(out)\n",
    "result = [(a == b).all() for a, b in zip(majority_pred, total_y_test[0:443])]\n",
    "raw = VanillaRNN2.evaluate(total_X_test, total_y_test)\n",
    "print(\"Raw Acc result: {}\".format(raw[1]))\n",
    "print(\"Majority Vote result: {}\".format(np.mean(result)))\n",
    "filepath = join(save_path, 'VanillaRNN.pickle')\n",
    "replace_model_if_better(filepath, np.mean(result), VanillaRNN2, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3101/3101 [==============================] - 0s 132us/step\n",
      "Raw Acc result: 0.5775556564331055\n",
      "Majority Vote result: 0.5959367945823928\n",
      "No existing model in specified path. Saving the new model\n"
     ]
    }
   ],
   "source": [
    "# Load the checkpointed model with highest val acc and perform majority voting\n",
    "model_path = join(workpath, '*.hdf5')\n",
    "list_of_files = glob.glob(model_path)\n",
    "latest_file = max(list_of_files, key=getctime)\n",
    "model_val = load_model(latest_file)\n",
    "preds = [model_val.predict(total_X_test[i::443], verbose=0) \n",
    "         for i in range(443)]\n",
    "majority_pred = []\n",
    "for pred in preds:\n",
    "    arg_maxes = [np.argmax(p) for p in pred]\n",
    "    votes = np.bincount(arg_maxes)\n",
    "    out = np.ndarray(shape=(4,), buffer=np.zeros(4), dtype=int)\n",
    "    out[votes.argmax()] = 1\n",
    "    majority_pred.append(out)\n",
    "result = [(a == b).all() for a, b in zip(majority_pred, total_y_test[0:443])]\n",
    "raw = model_val.evaluate(total_X_test, total_y_test)\n",
    "print(\"Raw Acc result: {}\".format(raw[1]))\n",
    "print(\"Majority Vote result: {}\".format(np.mean(result)))\n",
    "filepath = join(save_path, 'best_val', 'ConvMixGRU_val.pickle')\n",
    "replaced = replace_model_if_better(filepath, np.mean(result), model_val, config)\n",
    "rmtree(workpath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
